{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![avatar](pytorch.png)\n\nOfficial website: [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)","metadata":{}},{"cell_type":"code","source":"# pip install torch torchvision numpy matplotlib\nimport torch\nfrom torch import nn\nimport torch.nn.functional as func\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:00:29.650163Z","iopub.execute_input":"2021-12-18T22:00:29.650426Z","iopub.status.idle":"2021-12-18T22:00:29.655874Z","shell.execute_reply.started":"2021-12-18T22:00:29.650398Z","shell.execute_reply":"2021-12-18T22:00:29.654951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train transformation\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n# Test transformation\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Download training data from open datasets.\ntraining_data = datasets.CIFAR10(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=train_transform,\n)\n\n# Download test data from open datasets.\ntest_data = datasets.CIFAR10(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=test_transform,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:00:33.468672Z","iopub.execute_input":"2021-12-18T22:00:33.468952Z","iopub.status.idle":"2021-12-18T22:00:43.604213Z","shell.execute_reply.started":"2021-12-18T22:00:33.468915Z","shell.execute_reply":"2021-12-18T22:00:43.603481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training batch size\nbatch_size = 256\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size, num_workers=2, pin_memory=True)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size, num_workers=2, pin_memory=True)\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.figure(figsize=(15,15))\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n# Each batch tensor shape\nfor X, y in test_dataloader:\n    print(\"Shape of X [N, C, H, W]: \", X.shape)\n    print(\"Shape of y: \", y.shape, y.dtype)\n    \n    imshow(torchvision.utils.make_grid(X, nrow=20))\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:00:46.091338Z","iopub.execute_input":"2021-12-18T22:00:46.091604Z","iopub.status.idle":"2021-12-18T22:00:50.142832Z","shell.execute_reply.started":"2021-12-18T22:00:46.091579Z","shell.execute_reply":"2021-12-18T22:00:50.14187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.conv_relu_stack = nn.Sequential(\n            nn.Conv2d(3, 8, 7),\n            nn.ReLU(),\n            nn.Conv2d(8, 64,7),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 7),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, 3),\n            nn.ReLU(),\n            nn.Conv2d(256, 512, 3),\n            nn.ReLU(),\n            nn.Conv2d(512, 1024, 3),\n            nn.ReLU(),\n            nn.Conv2d(1024, 2048, 3),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(3)\n        )\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(18432, 512),\n        )\n\n    def forward(self, x):\n        x = self.conv_relu_stack(x)\n        # print(x.shape)\n        x = self.flatten(x)\n        # print(x.shape)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = models.efficientnet_b7(pretrained=True)\nmodel.cuda()\n# for X, y in test_dataloader:\n#     output = model(X)\n#     break\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:00:57.731986Z","iopub.execute_input":"2021-12-18T22:00:57.732356Z","iopub.status.idle":"2021-12-18T22:01:09.059633Z","shell.execute_reply.started":"2021-12-18T22:00:57.73232Z","shell.execute_reply":"2021-12-18T22:01:09.058807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loss function\nloss_fn = nn.CrossEntropyLoss()\n\n# SGD Optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.05, weight_decay=1e-4, momentum = 0.9)\n#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:01:20.040022Z","iopub.execute_input":"2021-12-18T22:01:20.040322Z","iopub.status.idle":"2021-12-18T22:01:20.050538Z","shell.execute_reply.started":"2021-12-18T22:01:20.040288Z","shell.execute_reply":"2021-12-18T22:01:20.049642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Training function\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    \n    # Turn on training mode\n    model.train()\n    train_loss, correct = 0, 0\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # record loss\n        train_loss += loss.item()\n        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    \n    train_loss /= len(dataloader)\n    correct /= size\n    \n    print(f\" Train accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:01:24.769472Z","iopub.execute_input":"2021-12-18T22:01:24.769743Z","iopub.status.idle":"2021-12-18T22:01:24.778024Z","shell.execute_reply.started":"2021-12-18T22:01:24.769716Z","shell.execute_reply":"2021-12-18T22:01:24.776991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test function\ndef test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    \n    # Turn on evalution mode\n    model.eval()\n    test_loss, correct = 0, 0\n    \n    # Turn off gradient descent\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            \n            # record loss\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n            \n    test_loss /= num_batches\n    correct /= size\n    \n    print(f\" Test accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:01:47.973045Z","iopub.execute_input":"2021-12-18T22:01:47.973349Z","iopub.status.idle":"2021-12-18T22:01:47.981779Z","shell.execute_reply.started":"2021-12-18T22:01:47.973321Z","shell.execute_reply":"2021-12-18T22:01:47.979967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total training epochs\nepochs = 250\n\nfor t in range(epochs):\n    print('\\n', \"=\" * 15, \"Epoch\", t + 1, \"=\" * 15)\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\" Done!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T22:01:51.279314Z","iopub.execute_input":"2021-12-18T22:01:51.279625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving model weights\n# torch.save(model)\ntorch.save(model.state_dict(), \"model.pth\")\nprint(\" Saved PyTorch Model State to model.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-12-18T21:45:37.765811Z","iopub.status.idle":"2021-12-18T21:45:37.766355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build the network\nmodel = NeuralNetwork()\n\n# Load trained weights\nmodel.load_state_dict(torch.load(\"model.pth\"))","metadata":{"execution":{"iopub.status.busy":"2021-12-18T21:45:37.767402Z","iopub.status.idle":"2021-12-18T21:45:37.767965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10 Classes\nclasses = [\n    \"Airplane\",\n    \"Automobile\",\n    \"Bird\",\n    \"Cat\",\n    \"Deer\",\n    \"Dog\",\n    \"Frog\",\n    \"Horse\",\n    \"Ship\",\n    \"Truck\",\n]\n\n# Evaluation mode\nmodel.eval()\n\n# Get one sample\nx, y = torch.tensor(test_data.data[10]).float().unsqueeze(0), test_data.targets[10]\n# print(x.shape)\n# x, y = test_data.data[0], test_data.targets[1]\n\n# Turn off gradient descent\nwith torch.no_grad():\n    pred = model(x)\n    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n    print(f' Predicted: \"{predicted}\", Actual: \"{actual}\"')","metadata":{"execution":{"iopub.status.busy":"2021-12-18T21:45:37.769022Z","iopub.status.idle":"2021-12-18T21:45:37.769588Z"},"trusted":true},"execution_count":null,"outputs":[]}]}