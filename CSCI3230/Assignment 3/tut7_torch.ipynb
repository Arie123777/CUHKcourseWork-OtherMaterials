{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](pytorch.png)\n",
    "\n",
    "Official website: [https://pytorch.org](https://pytorch.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is the mostly used deep learning library now, especially for research usage. In this tutorial, some basic knowledge and usage of PyTorch will be introduced.\n",
    "\n",
    "Here we will start from `tensors`. I think you all are familiar with `arrays` now as Mr. Yuehao has given you a tutorial on `NumPy`. \n",
    "\n",
    "`Tensors` are a specialized data structure that are very similar to `arrays`. In PyTorch, we use `tensors` to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
    "\n",
    "Actually, `tensors` are similar to `NumPy`’s `ndarrays`, except that `tensors` can run on GPUs or other hardware accelerators. Besides, `tensors` are also optimized for automatic differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import `PyTorch` and `NumPy` library at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch numpy\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Directly from data\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "print(type(data), type(x_data))\n",
    "\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# From a NumPy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(type(np_array))\n",
    "print(type(x_np))\n",
    "\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2208, 0.8925],\n",
      "        [0.9794, 0.4681]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.7628, 0.1688, 0.9701],\n",
      "        [0.3126, 0.7747, 0.2370]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# With random or constant values\n",
    "shape = (2, 3)\n",
    "rand_tensor = torch.rand(shape) # [0, 1)\n",
    "ones_tensor = torch.ones(shape) \n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "array1 = np.random.rand(3, 4)\n",
    "print(array1.shape)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6757, 0.9401, 0.0712, 0.3726],\n",
       "        [0.4599, 0.9171, 0.8886, 0.9471],\n",
       "        [0.8193, 0.0179, 0.4294, 0.9568]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    \n",
    "tensor.cpu()\n",
    "tensor.to('cpu')\n",
    "\n",
    "# device_ids = [0, 1, 2, 3]\n",
    "# tensor.to('cuda:1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4974, 0.1488, 0.3186],\n",
      "        [0.5636, 0.3844, 0.7200],\n",
      "        [0.4794, 0.2082, 0.3376]])\n",
      "First row:  tensor([0.4974, 0.1488, 0.3186])\n",
      "First column:  tensor([0.4974, 0.5636, 0.4794])\n",
      "Last column: tensor([0.3186, 0.7200, 0.3376])\n",
      "tensor([[0.4974, 0.0000, 0.3186],\n",
      "        [0.5636, 0.0000, 0.7200],\n",
      "        [0.4794, 0.0000, 0.3376]])\n",
      "tensor([[1.0000, 1.0000, 1.0000],\n",
      "        [0.5636, 0.0000, 0.7200],\n",
      "        [0.4794, 0.0000, 0.3376]])\n"
     ]
    }
   ],
   "source": [
    "# Standard numpy-like indexing and slicing:\n",
    "tensor = torch.rand(3, 3)\n",
    "print(tensor)\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:, 1] = 0\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "tensor[0, :] = 1\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.5636, 0.0000, 0.7200, 0.5636, 0.0000, 0.7200, 0.5636, 0.0000, 0.7200],\n",
      "        [0.4794, 0.0000, 0.3376, 0.4794, 0.0000, 0.3376, 0.4794, 0.0000, 0.3376]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate tensors\n",
    "# np.concatenate(axis=1)\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = torch.matmul(tensor, tensor.T)\n",
    "print(torch.equal(y1, y2)) # judge if y1 = y2\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = torch.mul(tensor, tensor)\n",
    "print(torch.equal(z1, z2)) # judge if y1 = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1005)\n",
      "5.100515842437744 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Single-element tensors \n",
    "\n",
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bridge with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy array to Tensor\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "print(n)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training neural networks, the most frequently used algorithm is **back propagation**. In this algorithm, parameters (model weights) are adjusted according to the **gradient** of the loss function with respect to the given parameter.\n",
    "\n",
    "To compute those gradients, PyTorch has a built-in differentiation engine called `torch.autograd`. It supports automatic computation of gradient for any computational graph.\n",
    "\n",
    "Consider the simplest one-layer neural network, with input `x`, parameters `w` and `b`, and some loss function. It can be defined in PyTorch in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines the following **computational graph**:\n",
    "\n",
    "![avatar](comp-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this network, `w` and `b` are parameters, which we need to optimize. Thus, we need to be able to compute the gradients of loss function with respect to those variables. In order to do that, we set the `requires_grad` property of those tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize weights of parameters in the neural network, we need to\n",
    "compute the derivatives of our loss function with respect to parameters,\n",
    "namely, we need $\\frac{\\partial loss}{\\partial w}$ and\n",
    "$\\frac{\\partial loss}{\\partial b}$ under some fixed values of\n",
    "``x`` and ``y``. To compute those derivatives, we call\n",
    "``loss.backward()``, and then retrieve the values from ``w.grad`` and\n",
    "``b.grad``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3003, 0.1218, 0.1951],\n",
      "        [0.3003, 0.1218, 0.1951],\n",
      "        [0.3003, 0.1218, 0.1951],\n",
      "        [0.3003, 0.1218, 0.1951],\n",
      "        [0.3003, 0.1218, 0.1951]])\n",
      "torch.Size([5, 3])\n",
      "tensor([0.3003, 0.1218, 0.1951])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(w.grad.shape)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all tensors with ``requires_grad=True`` are tracking their\n",
    "computational history and support gradient computation. However, there\n",
    "are some cases when we do not need to do that, for example, when we have\n",
    "trained the model and just want to apply it to some input data, i.e. we\n",
    "only want to do *forward* computations through the network. We can stop\n",
    "tracking computations by surrounding our computation code with\n",
    "``torch.no_grad()`` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to achieve the same result is to use the ``detach()`` method\n",
    "on the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are reasons you might want to disable gradient tracking:\n",
    "  - To mark some parameters in your neural network as **frozen parameters**. This is\n",
    "    a very common scenario for [finetuning a pretrained network](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)\n",
    "  - To **speed up computations** when you are only doing forward pass, because computations on tensors that do\n",
    "    not track gradients would be more efficient."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39a2d4910df682aa9922790387742797d4d7a07d73b97f20ec05364ed06a3619"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
